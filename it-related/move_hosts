#!/usr/bin/env python

'''
    Take a group of csv files, build a 2 column map of old name to new name

    Various output formats supported, see --help for details.

'''

import argparse
import csv
import logging
import os
import sys

logger = logging.getLogger(__name__)


def check_files(file_list, old_key, new_key, short_names, key, regexp):
    # find all files in error, return map
    if key:
        filter_re = re.compile(regexp)
    name_map = {}
    fail = False
    for f in file_list:
        if not os.path.exists(f):
            logging.error("No such file '%s'", f)
            fail = True
        else:
            csv_file = csv.DictReader(open(f, 'r'))
            for row in csv_file:
                try:
                    if key and not filter_re.search(row):
                        continue
                    old = row[old_key]
                    new = row[new_key]
                    if short_names:
                        old = old.split('.')[0]
                        new = new.split('.')[0]
                    name_map[old] = new
                except KeyError:
                    logging.error("missing keys in '%s'", f)
                    fail = True
                    break
    return name_map


def main():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('--old-key', '-o', dest="old_key",
                        default="old-hostname",
                        help="Column header for old host name")
    parser.add_argument('--new-key', '-n', dest="new_key", default="hostname",
                        help="Column header for new host name")
    parser.add_argument('--new-first', dest="new_first", default=False,
                        action="store_true",
                        help="ouput csv with new hostname first")
    parser.add_argument('--re-key', dest='filter_key', default=None,
                        metavar="COLUMN", help="filter on COLUMN using REGEXP")
    parser.add_argument('--re-str', dest='filter_regex', default=r'\S',
                        metavar='REGEXP',
                        help="regex COLUMN needs to match (default non-blank)")
    parser.add_argument('--short', dest='short_names', action='store_true',
                        default=False,
                        help="output just the host names, not the FQDN")
    parser.add_argument('--graphserver', dest='sql_graphserver', default=False,
                        action='store_true',
                        help="output SQL commands to update graphserver db")
    parser.add_argument('--slavealloc', dest='sql_slavealloc', default=False,
                        action='store_true',
                        help="output SQL commands to update slavealloc db")
    parser.add_argument('--csv', dest='csv', default=False, action='store_true',
                        help='Preserve column headers in output')
    parser.add_argument('files', metavar='FILE', nargs='+',
                        help='csv format file with header')
    args = parser.parse_args()
    # sanity checks
    changed_only = False
    if args.sql_graphserver and args.sql_slavealloc:
        parser.error("Can only specify one SQL output at a time")
    elif args.sql_graphserver or args.sql_slavealloc:
        if args.csv:
            parser.error("CSV and SQL output can't be mixed")
        elif args.new_first:
            parser.error("new first incompatible with SQL output")
        else:
            # Any SQL implies --short & that we only want changes
            changed_only = True
            args.short_names = True
    host_map = check_files(args.files, args.old_key, args.new_key,
                           args.short_names, args.filter_key,
                           args.filter_regex)
    if args.sql_graphserver:
        template = '''UPDATE machines SET name="%(new)s" ''' \
                   '''WHERE name="%(old)s";'''
    elif args.sql_slavealloc:
        template = '''Update slaves s JOIN datacenters dc on dc.name='scl3'
              set s.dcid = dc.dcid, s.name='%(new)s'
              where s.name = '%(old)s';'''
    elif args.new_first:
        template = '''%(new)s,%(old)s'''
    else:
        template = '''%(old)s,%(new)s'''
    ctx = {}
    if args.csv:
        # turn output into CSV file by adding header line.
        ctx['old'] = args.old_key
        ctx['new'] = args.new_key
        print template % ctx
    for ctx['old'], ctx['new'] in sorted(host_map.items()):
        # for sql output, only generate a line if change
        if changed_only and ctx['old'] == ctx['new']:
            continue
        print template % ctx
    return 0


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')
    sys.exit(main())
